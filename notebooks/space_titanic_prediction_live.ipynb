{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63048fb0",
   "metadata": {},
   "source": [
    "# Space Titanic Competition\n",
    "\n",
    "Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n",
    "\n",
    "The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n",
    "\n",
    "While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",
    "\n",
    "To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n",
    "\n",
    "Help save them and change history!\n",
    "\n",
    "<img src=\"images/competition_image.jpeg\" width=\"500\">\n",
    "\n",
    "[link to competition homepage](https://www.kaggle.com/c/spaceship-titanic/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5511a9",
   "metadata": {},
   "source": [
    "### Evaluation Criteria\n",
    "\n",
    "Submissions are evaluated based on their classification accuracy, the percentage of predicted labels that are correct.\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Where TP = True Positives, TN = True Negatives, FP = False Positives, and FN = False Negatives.\n",
    "\n",
    "### Submission Format\n",
    "\n",
    "The submission format for the competition is a csv file with the following format:\n",
    "\n",
    ">PassengerId,Transported<br>\n",
    ">0013_01,False<br>\n",
    ">0018_01,False<br>\n",
    ">0019_01,False<br>\n",
    ">0021_01,False<br>\n",
    ">etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f41bfe",
   "metadata": {},
   "source": [
    "In this competition your task is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly. To help you make these predictions, you're given a set of personal records recovered from the ship's damaged computer system.\n",
    "\n",
    "### File and Data Field Descriptions\n",
    "* train.csv - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "    * PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "    * HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "    * CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "    * Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "    * Destination - The planet the passenger will be debarking to.\n",
    "    * Age - The age of the passenger.\n",
    "    * VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "    * RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "    * Name - The first and last names of the passenger.\n",
    "    * Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "* test.csv - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
    "* sample_submission.csv - A submission file in the correct format.\n",
    "    * PassengerId - Id for each passenger in the test set.\n",
    "    * Transported - The target. For each passenger, predict either True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0527c0b7",
   "metadata": {},
   "source": [
    "### Questions before we start\n",
    "\n",
    "* What do you think are the \"easiest\" features to start with?\n",
    "* What engineered features can you think of?\n",
    "    * What will we need to do to create these features?\n",
    "* What do you *think* will be the most influential factor?\n",
    "* Some of these features are numeric, others are non-numeric categorical features. What type of pre-processing do you need to do to make these features readable for our model fitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8076b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd3a2f",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "**Instructions:**\n",
    "The first thing you need to do is load your data. syntax for pandas read_csv is below. You will need to do this for both testing and training data (two separate dataframes). I'll be using `df_train` and `df_test`.\n",
    "\n",
    "`df = pd.read_csv(file)`\n",
    "    \n",
    "**hints**: \n",
    "\n",
    "Testing data are in `./data/test.csv`\n",
    "\n",
    "Training data are in `./data/train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07451dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6352e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5eb8ab9",
   "metadata": {},
   "source": [
    "### Fill NaN values\n",
    "\n",
    "**Instructions:** There are multiple ways to do this. For now, let's use the *mode* of each column to fill in the NaN values.\n",
    "\n",
    "**hints:**\n",
    "\n",
    "This command will show you how many NaNs are in each column of a dataframe: `df.isna().sum()`\n",
    "\n",
    "To fill the NaN values for a column named `col` inplace with the mode, use: `df[col].fillna(df[col].mode()[0], inplace=True)`\n",
    "\n",
    "To get a list of columns, use: `df.columns.tolist()`\n",
    "\n",
    "Remember to do this for both training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8835aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc7dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b6620fe",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "\n",
    "**Instructions:** It's important to understand the data you are working with. Take this time to look at your data in the dataframe and using visualization. You can use either matplotlib or seaborn, but I'll give a few useful hints below.\n",
    "\n",
    "Start by looking at these features: 'HomePlanet', 'Destination', 'CryoSleep', 'VIP', 'Age'\n",
    "\n",
    "**hints:**\n",
    "\n",
    "To show the first five rows of a dataframe: `df.head(5)`\n",
    "\n",
    "To show the value counts in a column `col`: `df[col].value_counts()`\n",
    "\n",
    "To plot the value counts as a bar plot for a column `col`: `df[col].value_counts().plot.bar()`\n",
    "\n",
    "To plot a histogram of a column `col`: `df[col].plot.hist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f61ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35dfa126",
   "metadata": {},
   "source": [
    "**Edit this cell with your observations**\n",
    "\n",
    "Notes: Write down your observations about each of these features:\n",
    "* Home Planet\n",
    "* Destination\n",
    "* Cryo Sleep\n",
    "* VIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b054721",
   "metadata": {},
   "source": [
    "**Edit this cell with your observations**\n",
    "\n",
    "Notes: Write down your observations about age distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283002e",
   "metadata": {},
   "source": [
    "### Function definition cells (edit these at your own risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_x(df_train, df_test, y, features, encoded_features):\n",
    "    \"\"\" \n",
    "    Pre-process the data to prepare it for model fitting.\n",
    "    \n",
    "    Parameters:\n",
    "        df_train: Training dataframe\n",
    "        df_test: Testing dataframe\n",
    "        y: Targets\n",
    "        features: List of features to use\n",
    "        encoded features: List of features that need to be encoded\n",
    "    \n",
    "    Returns:\n",
    "        X_train: Training features\n",
    "        X_val: Validation features\n",
    "        X_test: Testing features\n",
    "        y_train: Training targets\n",
    "        y_val: Validation targets\n",
    "    \"\"\"\n",
    "    \n",
    "    # define X values as a subset of the dataframe\n",
    "    X = df_train[features]\n",
    "    X_test = df_test[features]\n",
    "    \n",
    "    # Use label encoder to make non-numeric features integers\n",
    "    for feature in encoded_features:\n",
    "        le_x = preprocessing.LabelEncoder()\n",
    "        le_x.fit(X[feature])\n",
    "        X.loc[:,feature] = le_x.transform(X[feature])\n",
    "        X_test.loc[:,feature] = le_x.transform(X_test[feature])\n",
    "\n",
    "    # Split into training and validation data\n",
    "    X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ea660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification(clf, features, X_train, y_train, X_val, y_val, X_test):\n",
    "    \"\"\"\n",
    "    Given a classifier and a set of features, fit the model.\n",
    "    \n",
    "    Parameters:\n",
    "        clf: Classifier from sklearn\n",
    "        features: List of features to use\n",
    "        X_train: Training features\n",
    "        y_train: Training targets\n",
    "        X_val: Validation features\n",
    "        y_val: Validation targets\n",
    "        X_test: Testing features\n",
    "        \n",
    "    Returns:\n",
    "        y_test_pred: Predicted test targets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit to training data and predict for validation data\n",
    "    pipe = pipeline.make_pipeline(preprocessing.StandardScaler(), clf)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_val_pred = pipe.predict(X_val)\n",
    "    \n",
    "    # Print the accuracy score\n",
    "    print(f'Accuracy: {pipe.score(X_val, y_val)}')\n",
    "    \n",
    "    # Make the confusion matrix and display it\n",
    "    cm = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                          display_labels=pipe.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate feature importances, print them, and display them\n",
    "    feature_importance = pipe.steps[1][1].feature_importances_.tolist()\n",
    "\n",
    "    print('Feature importance:')\n",
    "    for i in np.arange(len(feature_importance)):\n",
    "        print(features[i], '\\t', feature_importance[i])\n",
    "    \n",
    "    plt.bar(features, feature_importance)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xticks(rotation = 90);\n",
    "    plt.show()\n",
    "    \n",
    "    # Try it on the test data for submission\n",
    "    y_test_pred = pipe.predict(X_test)\n",
    "    \n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf4f2e",
   "metadata": {},
   "source": [
    "## Phase 1: Simple model with limited features\n",
    "\n",
    "**Instructions:**\n",
    "For our initial model, we'll define a set of simple features. Let's start with 'HomePlanet', 'Destination', 'CryoSleep', 'VIP', and 'Age'. Note that all of these except Age are non-numeric categorical features that need to be encoded. The target data also need to be converted to integer values (0, 1) rather than boolean values (False, True).\n",
    "\n",
    "**hints:**\n",
    "For the simple case, I'll give you the syntax. For the complex case, you'll need to do more typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features\n",
    "simple_features = ['HomePlanet', 'Destination', 'CryoSleep', 'VIP', 'Age']\n",
    "\n",
    "# List of non-numeric features\n",
    "encoded_simple_features = ['HomePlanet', 'Destination', 'CryoSleep', 'VIP']\n",
    "\n",
    "# Target column name\n",
    "target_col = 'Transported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target column\n",
    "df_targets = df_train[target_col]\n",
    "\n",
    "# Convert target to integer type\n",
    "y = df_targets.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pre-processing for the simple features list\n",
    "X_train, X_val, X_test, y_train, y_val = preprocessing_x(df_train, \n",
    "                                                        df_test, y, simple_features, \n",
    "                                                        encoded_simple_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64628a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random forest classifier \n",
    "clf = ensemble.RandomForestClassifier()\n",
    "\n",
    "# Run the classification\n",
    "y_test_pred = make_classification(clf, simple_features, X_train, \n",
    "                                  y_train, X_val, y_val, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6eb849",
   "metadata": {},
   "source": [
    "**Edit this cell with your observations**\n",
    "\n",
    "Notes: Write down your observations below.\n",
    "* How are we doing so far? Is this a 'good' score?\n",
    "* Which are the most important features? The least important?\n",
    "    * Does this surprise you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a892e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell shows how to save the data to csv, but let's not mess with that right now\n",
    "# y_simple_submission = pd.DataFrame({'PassengerId': df_test.PassengerId, \n",
    "#                                     'Transported': y_test_pred.astype(bool)})\n",
    "# y_simple_submission.to_csv('./data/simple_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ca4cc",
   "metadata": {},
   "source": [
    "## Phase 2: Complex model with added features\n",
    "\n",
    "**Instructions:**\n",
    "For our second model, we'll define a set of expanded features.\n",
    "\n",
    "* It's worth noting that `Cabin` actually contains three values: deck/num/side\n",
    "    * Probably deck and side are more significant than num\n",
    "* Perhaps the total amount spent across 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', and 'VRDeck' would be an interesting feature to include?\n",
    "* If someone is traveling with a group, could it be possible that they either transport or not together?\n",
    "    * Let's assume that the group is important, but the number in the group isn't\n",
    "\n",
    "**hints:**\n",
    "\n",
    "If you have a column that contains text that you want to split on the `/` character, the following may be helpful: `df[['col1', 'col2', 'col3']] = df[col].str.split(pat=\"/\", expand=True)`\n",
    "\n",
    "Similarly, if you want to split on `_`, you could use: `df[['col1', 'col2']] = df[col].str.split(pat=\"_\", expand=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f095285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5321ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c84b6c5",
   "metadata": {},
   "source": [
    "**Edit this cell with your observations**\n",
    "\n",
    "Notes: Write down your observations below.\n",
    "* How are we doing so far? Is this a 'better' score?\n",
    "* Which are the most important features? The least important?\n",
    "    * Are there any new features that are praticularly useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6fd1d",
   "metadata": {},
   "source": [
    "### Random observation time:\n",
    "\n",
    "Something the suprised me was that the VIP status didn't matter more, but VIPs were less likely to be transported than non-VIPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b96c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['VIP']==True]['Transported'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['VIP']==False]['Transported'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accadbc8",
   "metadata": {},
   "source": [
    "## Phase 3: Optimize the hyper-parameters\n",
    "\n",
    "Okay, so we have a decent model. But notice that we didn't do ANY hyper-parameter tuning so far. We just went with the default values.\n",
    "\n",
    "For more about grid search, click [here](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    "We will be using a randomized search. See [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV) for more details.\n",
    "\n",
    "\n",
    "**I'm giving these cells to you \"for free\" but you can feel free to mess around with the values and such if you'd like.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc884c0",
   "metadata": {},
   "source": [
    "Note: credit for the following few cells goes to this article: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9bf602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our randomized grid search\n",
    "clf_random = model_selection.RandomizedSearchCV(estimator = clf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 30, cv = 3, verbose=2, \n",
    "                               random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best fit\n",
    "clf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5856913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "clf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf33dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the classification model with the best estimator\n",
    "best_random = clf_random.best_estimator_\n",
    "y_test_pred = make_classification(best_random, complex_features, \n",
    "                                  X_train, y_train, X_val, y_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data writing cell\n",
    "# y_best_submission = pd.DataFrame({'PassengerId': df_test.PassengerId, \n",
    "#                                     'Transported': y_test_pred.astype(bool)})\n",
    "# y_best_submission.to_csv('./data/best_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d73b3",
   "metadata": {},
   "source": [
    "**Edit this cell with your observations**\n",
    "\n",
    "Notes: Write down your observations below.\n",
    "* How did we do? Is this the 'best' score?\n",
    "* Did tuning improve the score?\n",
    "* Would tuning matter more or less in other models?\n",
    "* Take a look at the [leaderboard](https://www.kaggle.com/c/spaceship-titanic/leaderboard#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42b643",
   "metadata": {},
   "source": [
    "## Phase 4: Freeform time\n",
    "\n",
    "Want to play aorund with some other models? Retune parameters? Add more features? Here's your chance to try to improve. Work alone or ask you neighbor for help. Maybe form a team on kaggle and create your own submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c01cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
